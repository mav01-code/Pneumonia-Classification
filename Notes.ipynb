{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b07fa6b",
   "metadata": {},
   "source": [
    "Dataset -> Load the img -> Preprocess (Grayscale and Normalize) -> Feature extraction -> Dataset Matrix -> Train the model -> Predict -> Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2008654f",
   "metadata": {},
   "source": [
    "## 1) Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982fc5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open(\"img1.jpg\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d79f5a",
   "metadata": {},
   "source": [
    "## 2. Preprocess the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345048b",
   "metadata": {},
   "source": [
    "### 2.1 Convert to grayscale\n",
    "- We convert an image to grayscale to make the pre processing faster. \n",
    "- The colored image is made of pixels and each pixel contains 3 primary colors - Red, Green, Blue; also called RGB. \n",
    "- Meaning each pixel contains 3 channels - [R amount, G amount, B amount]. \n",
    "- But when we convert it into grayscale, it contains only one channel - [Gray amount] or the brightness percentage. \n",
    "- This reduces time taken to pre-process the image and helps in yielding better outcome faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22fd0e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.convert(\"L\")\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d3bed",
   "metadata": {},
   "source": [
    "### 2.2 Resize the image\n",
    "- Convert all the images to 128x128 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff0ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize((128, 128))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f7eb8",
   "metadata": {},
   "source": [
    "### 2.3 Convert the image into grid/matrix\n",
    "\n",
    "- Once the image is resized, we need to represent the brightness levels in each image in the form of matrix for numpy to perform numerical calculations.\n",
    "- Every image is divided into rows and columns. Each row represents horizontal line of pixels brightness in an image and each column represents vertical line of pixels brightness. \n",
    "- Each cell is the brightness value of that pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fcbba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120 123 128 ... 121 120 127]\n",
      " [135 135 134 ... 132 143 152]\n",
      " [150 150 149 ... 155 163 156]\n",
      " ...\n",
      " [ 18  58  62 ...  58  23   5]\n",
      " [ 16  62  64 ...  58  27   3]\n",
      " [ 15  59  65 ...  56  30   4]]\n"
     ]
    }
   ],
   "source": [
    "img_array = np.array(img)\n",
    "print(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6bc966",
   "metadata": {},
   "source": [
    "### 2.4 Normalize the array\n",
    "- Convert the int array into float values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c1f556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47058824 0.48235294 0.5019608  ... 0.4745098  0.47058824 0.49803922]\n",
      " [0.5294118  0.5294118  0.5254902  ... 0.5176471  0.56078434 0.59607846]\n",
      " [0.5882353  0.5882353  0.58431375 ... 0.60784316 0.6392157  0.6117647 ]\n",
      " ...\n",
      " [0.07058824 0.22745098 0.24313726 ... 0.22745098 0.09019608 0.01960784]\n",
      " [0.0627451  0.24313726 0.2509804  ... 0.22745098 0.10588235 0.01176471]\n",
      " [0.05882353 0.23137255 0.25490198 ... 0.21960784 0.11764706 0.01568628]]\n"
     ]
    }
   ],
   "source": [
    "img_array = img_array.astype(\"float32\")/255.0\n",
    "print(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357d0291",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8269d0a",
   "metadata": {},
   "source": [
    "### 3.1 Convert the img_array (2D) array into 1D array\n",
    "- We convert 2D to 1D array so it's easier to perform statistical operations like mean, standard deviation, minimum brightness, maximum brightness on feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6e2b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47058824 0.48235294 0.5019608  ... 0.21960784 0.11764706 0.01568628]\n"
     ]
    }
   ],
   "source": [
    "features = img_array.flatten()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a51c2",
   "metadata": {},
   "source": [
    "### 3.2 Find the statistical calculations and add them to feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e92cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47058824 0.48235294 0.5019608  ... 0.21838112 0.         0.9882353 ]\n"
     ]
    }
   ],
   "source": [
    "mean = features.mean()\n",
    "std = features.std()\n",
    "m = features.min()\n",
    "M = features.max()\n",
    "features = np.concatenate([features, [mean, std, m, M]])\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f8ebb",
   "metadata": {},
   "source": [
    "### 3.3 Convert the 1D to 2D because the classifier expects 2D - [number of images, number of features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee655f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47058824 0.48235294 0.5019608  ... 0.21838112 0.         0.9882353 ]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "X = features.reshape(1, -1)\n",
    "Y = [1]\n",
    "print(X)\n",
    "print(Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
